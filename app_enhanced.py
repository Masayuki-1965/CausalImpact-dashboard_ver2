import os
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import matplotlib.pyplot as plt
import io
from datetime import datetime
import base64
import tempfile
from PIL import Image
import plotly.io as pio
import plotly.figure_factory as ff
from reportlab.lib.pagesizes import letter, A4
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as ReportLabImage, Table, TableStyle
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib import colors
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.units import inch, mm
from reportlab.lib.enums import TA_CENTER, TA_LEFT

# å¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«import
from causal_impact_translator import translate_causal_impact_report
from utils_step1 import get_csv_files, load_and_clean_csv, make_period_key, aggregate_df, create_full_period_range, format_stats_with_japanese
from utils_step2 import get_period_defaults, validate_periods, calc_period_days, build_analysis_params
from utils_step3 import run_causal_impact_analysis, build_summary_dataframe, get_summary_csv_download_link, get_figure_pdf_download_link, get_detail_csv_download_link

# å‡¦ç½®ç¾¤ã®ã¿åˆ†æç”¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from utils_step3_single_group import (
    run_single_group_causal_impact_analysis, 
    validate_single_group_data, 
    suggest_intervention_point,
    build_single_group_summary_dataframe,
    get_single_group_interpretation
)

# ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œã®å¤–éƒ¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from config.constants import PAGE_CONFIG, CUSTOM_CSS_PATH
from config.help_texts import (
    DATA_FORMAT_GUIDE_HTML, FAQ_CAUSAL_IMPACT, FAQ_STATE_SPACE_MODEL,
    HEADER_CARD_HTML, STEP1_CARD_HTML, STEP2_CARD_HTML, STEP3_CARD_HTML,
    RESET_GUIDE_HTML, SIDEBAR_FLOW_DESCRIPTION
)
from utils_common import load_css, initialize_session_state, reset_session_state, get_step_status

# --- åˆæœŸåŒ– ---
initialize_session_state()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åˆ†æã‚¿ã‚¤ãƒ—ã‚’è¿½åŠ 
if 'analysis_type' not in st.session_state:
    st.session_state.analysis_type = "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰"

# --- ç”»é¢å¹…ã‚’æœ€å¤§åŒ– ---
st.set_page_config(**PAGE_CONFIG)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSèª­ã¿è¾¼ã¿ ---
load_css(CUSTOM_CSS_PATH)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.markdown('<div class="sidebar-title">åˆ†æãƒ•ãƒ­ãƒ¼</div>', unsafe_allow_html=True)
    st.markdown(SIDEBAR_FLOW_DESCRIPTION, unsafe_allow_html=True)
    
    # STEPã®ã‚¢ã‚¯ãƒ†ã‚£ãƒ–çŠ¶æ…‹ã‚’å–å¾—
    step_status = get_step_status()
    
    st.markdown(f"""
    <div style="margin-top:0.5em;">
        <div class="{'sidebar-step-active' if step_status['step1'] else 'sidebar-step-inactive'}">STEP 1ï¼šãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿ï¼å¯è¦–åŒ–</div>
        <div class="{'sidebar-step-active' if step_status['step2'] else 'sidebar-step-inactive'}">STEP 2ï¼šåˆ†ææœŸé–“ï¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š</div>
        <div class="{'sidebar-step-active' if step_status['step3'] else 'sidebar-step-inactive'}">STEP 3ï¼šåˆ†æå®Ÿè¡Œï¼çµæœç¢ºèª</div>
    </div>
    <div class="separator-line"></div>
    """, unsafe_allow_html=True)
    
    # æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™æ¡ˆå†…æ–‡
    st.markdown('<div style="margin-top:15px;margin-bottom:10px;"></div>', unsafe_allow_html=True)
    st.markdown(RESET_GUIDE_HTML, unsafe_allow_html=True)

    with st.expander("Causal Impactã¨ã¯ï¼Ÿ", expanded=False):
        st.markdown(FAQ_CAUSAL_IMPACT, unsafe_allow_html=True)
    with st.expander("çŠ¶æ…‹ç©ºé–“ãƒ¢ãƒ‡ãƒ«ã¨ã¯ï¼Ÿ", expanded=False):
        st.markdown(FAQ_STATE_SPACE_MODEL, unsafe_allow_html=True)

# --- ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ ---
st.markdown(HEADER_CARD_HTML, unsafe_allow_html=True)

st.markdown(STEP1_CARD_HTML, unsafe_allow_html=True)

# --- ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¬ã‚¤ãƒ‰ ---
with st.expander("ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¬ã‚¤ãƒ‰", expanded=False):
    st.markdown(DATA_FORMAT_GUIDE_HTML, unsafe_allow_html=True)

# --- ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠUIã®ä»£ã‚ã‚Šã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ ---
st.markdown('<div class="section-title">åˆ†æå¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰</div>', unsafe_allow_html=True)

# åˆ†æã‚¿ã‚¤ãƒ—ã®é¸æŠ
st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">åˆ†æã‚¿ã‚¤ãƒ—ã®é¸æŠ</div>', unsafe_allow_html=True)
analysis_type = st.radio(
    "åˆ†æã‚¿ã‚¤ãƒ—é¸æŠ",
    options=["æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰", "å‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼ˆå¯¾ç…§ç¾¤ãªã—ï¼‰"],
    index=0,
    label_visibility="collapsed",
    help="æ¨™æº–åˆ†æã¯å‡¦ç½®ç¾¤ã¨å¯¾ç…§ç¾¤ã®ä¸¡æ–¹ã‚’æ¯”è¼ƒã—ã¾ã™ã€‚å‡¦ç½®ç¾¤ã®ã¿åˆ†æã¯ä»‹å…¥å‰å¾Œã®ãƒˆãƒ¬ãƒ³ãƒ‰å¤‰åŒ–ã‚’åˆ†æã—ã¾ã™ã€‚"
)

# åˆ†æã‚¿ã‚¤ãƒ—ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
st.session_state.analysis_type = analysis_type

# åˆ†æã‚¿ã‚¤ãƒ—ã«ã‚ˆã£ã¦èª¬æ˜ã‚’è¡¨ç¤º
if analysis_type == "å‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼ˆå¯¾ç…§ç¾¤ãªã—ï¼‰":
    st.info("ğŸ’¡ **å‡¦ç½®ç¾¤ã®ã¿åˆ†æ**ã§ã¯ã€ä»‹å…¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å­£ç¯€æ€§ã‚„ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å­¦ç¿’ã—ã€ä»‹å…¥å¾Œã®äºˆæ¸¬å€¤ï¼ˆåäº‹å®Ÿã‚·ãƒŠãƒªã‚ªï¼‰ã¨å®Ÿæ¸¬å€¤ã‚’æ¯”è¼ƒã—ã¦åŠ¹æœã‚’æ¸¬å®šã—ã¾ã™ã€‚")

# ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•åˆ‡ã‚Šæ›¿ãˆã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³
st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;margin-top:1em;">ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•ã®é¸æŠ</div>', unsafe_allow_html=True)
upload_method = st.radio(
    "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹æ³•é¸æŠ",
    options=["ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆâ€»æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã¯éå¯¾å¿œï¼è‹±æ•°å­—ã®ã¿ä½¿ç”¨å¯ï¼‰", "CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›"],
    index=0,
    label_visibility="collapsed",
    help="CSVãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥å…¥åŠ›ã™ã‚‹æ–¹æ³•ã¨ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹æ–¹æ³•ãŒã‚ã‚Šã¾ã™ã€‚"
)

# å¤‰æ•°ã®åˆæœŸåŒ–ï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰
treatment_file = None
control_file = None
treatment_csv = ""
control_csv = ""
treatment_name = "å‡¦ç½®ç¾¤"
control_name = "å¯¾ç…§ç¾¤"
read_btn_upload = False
read_btn_text = False
read_btn_single_upload = False
read_btn_single_text = False

# åˆ†æã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦UIã‚’åˆ‡ã‚Šæ›¿ãˆ
if analysis_type == "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰":
    # æ—¢å­˜ã®æ¨™æº–åˆ†æUI
    if upload_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆâ€»æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã¯éå¯¾å¿œï¼è‹±æ•°å­—ã®ã¿ä½¿ç”¨å¯ï¼‰":
        # å‡¦ç½®ç¾¤ã¨å¯¾ç…§ç¾¤ã®åç§°å…¥åŠ›æ¬„ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ»CSVãƒ†ã‚­ã‚¹ãƒˆå…±é€šï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
            
            treatment_file = st.file_uploader(
                "å‡¦ç½®ç¾¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
                type=['csv'], 
                key="treatment_upload", 
                help="å‡¦ç½®ç¾¤ï¼ˆåŠ¹æœã‚’æ¸¬å®šã—ãŸã„å¯¾è±¡ï¼‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
                accept_multiple_files=False,
                label_visibility="collapsed"
            )
            
            if treatment_file:
                file_basename = os.path.splitext(treatment_file.name)[0]
                treatment_name = file_basename
                selected_treat = f"é¸æŠï¼š{treatment_file.name}ï¼ˆå‡¦ç½®ç¾¤ï¼‰"
                st.markdown(f'<div style="color:#1976d2;font-size:0.9em;">{selected_treat}</div>', unsafe_allow_html=True)
            else:
                treatment_name = "å‡¦ç½®ç¾¤"
                
            treatment_name = st.text_input("å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›", value=treatment_name, key="treatment_name_upload", help="å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå•†å“Aã€åº—èˆ—B ãªã©ï¼‰")
            
        with col2:
            st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å¯¾ç…§ç¾¤ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
            
            control_file = st.file_uploader(
                "å¯¾ç…§ç¾¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
                type=['csv'], 
                key="control_upload", 
                help="å¯¾ç…§ç¾¤ï¼ˆæ¯”è¼ƒå¯¾è±¡ï¼‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
                accept_multiple_files=False,
                label_visibility="collapsed"
            )
            
            if control_file:
                file_basename = os.path.splitext(control_file.name)[0]
                control_name = file_basename
                selected_ctrl = f"é¸æŠï¼š{control_file.name}ï¼ˆå¯¾ç…§ç¾¤ï¼‰"
                st.markdown(f'<div style="color:#1976d2;font-size:0.9em;">{selected_ctrl}</div>', unsafe_allow_html=True)
            else:
                control_name = "å¯¾ç…§ç¾¤"
                
            control_name = st.text_input("å¯¾ç…§ç¾¤ã®åç§°ã‚’å…¥åŠ›", value=control_name, key="control_name_upload", help="å¯¾ç…§ç¾¤ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå•†å“Bã€åº—èˆ—C ãªã©ï¼‰")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³ï¼ˆæ¨™æº–åˆ†æãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
        st.markdown('<div style="margin-top:25px;"></div>', unsafe_allow_html=True)
        read_btn_upload = st.button("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="read_upload", help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚", type="primary", use_container_width=True, disabled=(not treatment_file or not control_file))

    else:
        # CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›ã®UIï¼ˆæ¨™æº–åˆ†æï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
            treatment_name = st.text_input("å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›", value="å‡¦ç½®ç¾¤", key="treatment_name_text", help="å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå•†å“Aã€åº—èˆ—B ãªã©ï¼‰")
            
            treatment_csv = st.text_area(
                "CSVãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ï¼ˆã‚«ãƒ³ãƒãƒ»ã‚¿ãƒ–ãƒ»ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
                height=200,
                help="CSVãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥å…¥åŠ›ã¾ãŸã¯ã‚³ãƒ”ãƒšã—ã¦ãã ã•ã„ã€‚æœ€ä½é™ã€ymdï¼ˆæ—¥ä»˜ï¼‰ã¨qtyï¼ˆæ•°é‡ï¼‰ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚",
                placeholder="ymd,qty\n20170403,29\n20170425,24\n20170426,23\n20170523,24\n20170524,26"
            )
            st.markdown('<div style="color:#555555;font-size:0.9em;margin-top:-5px;margin-bottom:15px;padding-left:5px;">ï¼ˆä¸Šã®å…¥åŠ›æ¬„ã«CSVãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒšã—ã¦ãã ã•ã„ï¼‰</div>', unsafe_allow_html=True)
        
        with col2:
            st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å¯¾ç…§ç¾¤ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
            control_name = st.text_input("å¯¾ç…§ç¾¤ã®åç§°ã‚’å…¥åŠ›", value="å¯¾ç…§ç¾¤", key="control_name_text", help="å¯¾ç…§ç¾¤ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå•†å“Bã€åº—èˆ—C ãªã©ï¼‰")
            
            control_csv = st.text_area(
                "CSVãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ï¼ˆã‚«ãƒ³ãƒãƒ»ã‚¿ãƒ–ãƒ»ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
                height=200,
                help="CSVãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥å…¥åŠ›ã¾ãŸã¯ã‚³ãƒ”ãƒšã—ã¦ãã ã•ã„ã€‚æœ€ä½é™ã€ymdï¼ˆæ—¥ä»˜ï¼‰ã¨qtyï¼ˆæ•°é‡ï¼‰ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚",
                placeholder="ymd,qty\n20170403,35\n20170425,30\n20170426,28\n20170523,29\n20170524,31"
            )
            st.markdown('<div style="color:#555555;font-size:0.9em;margin-top:-5px;margin-bottom:15px;padding-left:5px;">ï¼ˆä¸Šã®å…¥åŠ›æ¬„ã«CSVãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒšã—ã¦ãã ã•ã„ï¼‰</div>', unsafe_allow_html=True)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³ï¼ˆæ¨™æº–åˆ†æãƒ»CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›ç”¨ï¼‰
        st.markdown('<div style="margin-top:25px;"></div>', unsafe_allow_html=True)
        read_btn_text = st.button("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="read_text", help="å…¥åŠ›ã—ãŸCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚", type="primary", use_container_width=True, disabled=(not treatment_csv or not control_csv))

else:
    # å‡¦ç½®ç¾¤ã®ã¿åˆ†æUI
    if upload_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆâ€»æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã¯éå¯¾å¿œï¼è‹±æ•°å­—ã®ã¿ä½¿ç”¨å¯ï¼‰":
        st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
        
        treatment_file = st.file_uploader(
            "å‡¦ç½®ç¾¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", 
            type=['csv'], 
            key="treatment_single_upload", 
            help="å‡¦ç½®ç¾¤ï¼ˆåŠ¹æœã‚’æ¸¬å®šã—ãŸã„å¯¾è±¡ï¼‰ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚",
            accept_multiple_files=False,
            label_visibility="collapsed"
        )
        
        if treatment_file:
            file_basename = os.path.splitext(treatment_file.name)[0]
            treatment_name = file_basename
            selected_treat = f"é¸æŠï¼š{treatment_file.name}ï¼ˆå‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼‰"
            st.markdown(f'<div style="color:#1976d2;font-size:0.9em;">{selected_treat}</div>', unsafe_allow_html=True)
        else:
            treatment_name = "å‡¦ç½®ç¾¤"
            
        treatment_name = st.text_input("å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›", value=treatment_name, key="treatment_name_single_upload", help="å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå•†å“Aã€åº—èˆ—B ãªã©ï¼‰")
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³ï¼ˆå‡¦ç½®ç¾¤ã®ã¿ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”¨ï¼‰
        st.markdown('<div style="margin-top:25px;"></div>', unsafe_allow_html=True)
        read_btn_single_upload = st.button("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="read_single_upload", help="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚", type="primary", use_container_width=True, disabled=(not treatment_file))

    else:
        # CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›ã®UIï¼ˆå‡¦ç½®ç¾¤ã®ã¿ï¼‰
        st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ãƒ‡ãƒ¼ã‚¿</div>', unsafe_allow_html=True)
        treatment_name = st.text_input("å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›", value="å‡¦ç½®ç¾¤", key="treatment_name_single_text", help="å‡¦ç½®ç¾¤ã®åç§°ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šå•†å“Aã€åº—èˆ—B ãªã©ï¼‰")
        
        treatment_csv = st.text_area(
            "CSVãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ï¼ˆã‚«ãƒ³ãƒãƒ»ã‚¿ãƒ–ãƒ»ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šï¼‰",
            height=300,
            help="CSVãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥å…¥åŠ›ã¾ãŸã¯ã‚³ãƒ”ãƒšã—ã¦ãã ã•ã„ã€‚æœ€ä½é™ã€ymdï¼ˆæ—¥ä»˜ï¼‰ã¨qtyï¼ˆæ•°é‡ï¼‰ã®åˆ—ãŒå¿…è¦ã§ã™ã€‚å‡¦ç½®ç¾¤ã®ã¿åˆ†æã§ã¯æœ€ä½37æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚",
            placeholder="ymd,qty\n20170403,29\n20170425,24\n20170426,23\n20170523,24\n20170524,26\n...\nï¼ˆä»‹å…¥å‰å¾Œã‚’å«ã‚€ååˆ†ãªãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ï¼‰"
        )
        st.markdown('<div style="color:#555555;font-size:0.9em;margin-top:-5px;margin-bottom:15px;padding-left:5px;">ï¼ˆæœ€ä½37æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ¨å¥¨ã€ä»‹å…¥å‰æœŸé–“ã¯å…¨ä½“ã®60%ä»¥ä¸ŠãŒå¿…è¦ï¼‰</div>', unsafe_allow_html=True)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒœã‚¿ãƒ³ï¼ˆå‡¦ç½®ç¾¤ã®ã¿ãƒ»CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›ç”¨ï¼‰
        st.markdown('<div style="margin-top:25px;"></div>', unsafe_allow_html=True)
        read_btn_single_text = st.button("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€", key="read_single_text", help="å…¥åŠ›ã—ãŸCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚", type="primary", use_container_width=True, disabled=(not treatment_csv))

# --- ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•° ---
def load_and_clean_uploaded_csv(uploaded_file):
    try:
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãƒ­ã‚°ã«å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        file_name = uploaded_file.name
        print(f"å‡¦ç†ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«: {file_name}")
        
        # ãƒã‚¤ãƒˆåˆ—ã‚’èª­ã¿è¾¼ã¿
        file_bytes = uploaded_file.getvalue()
        
        # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°æ¤œå‡ºã®è©¦è¡Œå›æ•°ã‚’å¢—ã‚„ã™
        encodings = ['utf-8', 'shift-jis', 'cp932', 'euc-jp', 'iso-2022-jp', 'latin1']
        df = None
        
        # æ–¹æ³•1: ç›´æ¥StringIOã‚’ä½¿ç”¨
        for encoding in encodings:
            try:
                # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è¨­å®šã—ã¦èª­ã¿è¾¼ã¿è©¦è¡Œ
                content = file_bytes.decode(encoding)
                # ãƒ†ã‚¹ãƒˆç”¨ã«å…ˆé ­è¡Œã ã‘è§£æ
                test_df = pd.read_csv(io.StringIO(content.split('\n', 5)[0]), nrows=1)
                # æˆåŠŸã—ãŸã‚‰ã™ã¹ã¦ã‚’èª­ã¿è¾¼ã‚€
                df = pd.read_csv(io.StringIO(content))
                print(f"æ­£å¸¸ã«èª­ã¿è¾¼ã¿: ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° {encoding}")
                break
            except UnicodeDecodeError:
                continue
            except Exception as e:
                print(f"ã‚¨ãƒ©ãƒ¼ï¼ˆ{encoding}ï¼‰: {str(e)}")
                continue
        
        # ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚‚èª­ã¿è¾¼ã‚ãªã‹ã£ãŸå ´åˆ
        if df is None:
            try:
                # æ–¹æ³•2: BytesIOã‚’ç›´æ¥ä½¿ç”¨
                df = pd.read_csv(io.BytesIO(file_bytes))
                print("BytesIOã‚’ä½¿ç”¨ã—ã¦æ­£å¸¸ã«èª­ã¿è¾¼ã¿")
            except Exception as e2:
                try:
                    # æ–¹æ³•3: tempfileã‚’ä½¿ç”¨ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã«ä¾å­˜ã—ãªã„å‡¦ç†ï¼‰
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp_file:
                        tmp_file.write(file_bytes)
                        tmp_path = tmp_file.name
                    
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
                    df = pd.read_csv(tmp_path)
                    # èª­ã¿è¾¼ã¿å¾Œã«ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.unlink(tmp_path)
                    print("ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦æ­£å¸¸ã«èª­ã¿è¾¼ã¿")
                except Exception as e3:
                    print(f"å…¨ã¦ã®èª­ã¿è¾¼ã¿æ–¹æ³•ãŒå¤±æ•—: {str(e2)}, {str(e3)}")
                    st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    return None
        
        # ã‚«ãƒ©ãƒ åã®ç¢ºèªã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
        df.columns = [col.strip() for col in df.columns]
        
        # å¿…é ˆã‚«ãƒ©ãƒ ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        required_columns = ['ymd', 'qty']
        if not all(col in df.columns for col in required_columns):
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ ã®å ´åˆã¯ã€æœ€åˆã®2ã¤ã®ã‚«ãƒ©ãƒ ãŒymdã¨qtyã¨ä»®å®š
            if len(df.columns) >= 2:
                rename_dict = {df.columns[0]: 'ymd', df.columns[1]: 'qty'}
                df = df.rename(columns=rename_dict)
                st.info(f"ã‚«ãƒ©ãƒ åã‚’è‡ªå‹•è¨­å®šã—ã¾ã—ãŸ: {df.columns[0]} â†’ ymd, {df.columns[1]} â†’ qty")
            else:
                st.error(f"å¿…é ˆã‚«ãƒ©ãƒ  'ymd' ã¨ 'qty' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return None
        
        # æ—¥ä»˜ã®å‡¦ç†
        df['ymd'] = df['ymd'].astype(str).str.zfill(8)
        try:
            # ã¾ãš%Y%m%då½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ
            df['ymd'] = pd.to_datetime(df['ymd'], format='%Y%m%d', errors='coerce')
        except:
            try:
                # å¤±æ•—ã—ãŸå ´åˆã¯è‡ªå‹•æ¨å®šã§å¤‰æ›
                df['ymd'] = pd.to_datetime(df['ymd'], errors='coerce')
            except:
                st.error("æ—¥ä»˜åˆ—ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚YYYYMMDDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return None
        
        # ç„¡åŠ¹ãªæ—¥ä»˜ã‚’ãƒã‚§ãƒƒã‚¯
        invalid_dates = df[df['ymd'].isna()]
        if not invalid_dates.empty:
            st.warning(f"{len(invalid_dates)}è¡Œã®æ—¥ä»˜ãŒç„¡åŠ¹ãªãŸã‚é™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚YYYYMMDDå½¢å¼ï¼ˆä¾‹ï¼š20240101ï¼‰ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            df = df.dropna(subset=['ymd'])
        
        # æ¬ æå€¤ã‚’é™¤å¤–
        original_len = len(df)
        df = df.dropna(subset=['ymd'])
            
        # qtyåˆ—ã®æ•°å€¤å¤‰æ›ç¢ºèª
        try:
            df['qty'] = pd.to_numeric(df['qty'], errors='coerce')
            if df['qty'].isna().any():
                st.warning(f"{df['qty'].isna().sum()}è¡Œã®æ•°é‡(qty)ãŒæ•°å€¤ã«å¤‰æ›ã§ããªã„ãŸã‚é™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚")
                df = df.dropna(subset=['qty'])
        except Exception as e:
            st.error(f"æ•°é‡(qty)ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            return None
        
        if len(df) == 0:
            st.error("å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒ0è¡Œã«ãªã‚Šã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
            
        return df
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# --- ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‹ã‚‰CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€é–¢æ•° ---
def load_and_clean_csv_text(csv_text, source_name):
    try:
        # ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãƒã‚§ãƒƒã‚¯
        if not csv_text.strip():
            st.error(f"{source_name}ã®CSVãƒ‡ãƒ¼ã‚¿ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            return None
        
        # å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã®å‰å‡¦ç†ï¼ˆæ”¹è¡Œã¨åŒºåˆ‡ã‚Šæ–‡å­—ã®æ­£è¦åŒ–ï¼‰
        csv_text = csv_text.strip()
        # æœ€åˆã®è¡Œã‚’å–å¾—ã—ã¦ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’åˆ†æ
        lines = csv_text.split('\n')
        if len(lines) == 0:
            st.error(f"{source_name}ã®å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã«è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None
            
        # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®ãƒã‚§ãƒƒã‚¯ï¼ˆã‚¿ãƒ–åŒºåˆ‡ã‚Šã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã«å¯¾å¿œï¼‰
        header = lines[0]
        sep = None
        
        # åŒºåˆ‡ã‚Šæ–‡å­—ã®æ¤œå‡ºï¼ˆã‚¿ãƒ–ã€ã‚«ãƒ³ãƒã€ã‚¹ãƒšãƒ¼ã‚¹ã®é †ã§è©¦ã™ï¼‰
        if '\t' in header:
            sep = '\t'
        elif ',' in header:
            sep = ','
        elif ' ' in header and len(header.split()) > 1:
            sep = '\\s+'  # æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Š
        else:
            # åŒºåˆ‡ã‚Šæ–‡å­—ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã¨ä»®å®š
            sep = ','
        
        try:
            # åŒºåˆ‡ã‚Šæ–‡å­—ã‚’æŒ‡å®šã—ã¦CSVã‚’ãƒ‘ãƒ¼ã‚¹
            if sep == '\\s+':
                # æ­£è¦è¡¨ç¾ã®ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã®å ´åˆ
                df = pd.read_csv(io.StringIO(csv_text), sep=sep, engine='python')
            else:
                df = pd.read_csv(io.StringIO(csv_text), sep=sep)
        except Exception as e:
            st.error(f"{source_name}ã®CSVãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
            # ã‚¿ãƒ–åŒºåˆ‡ã‚Šã§ã‚‚ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã€ã‚¹ãƒšãƒ¼ã‚¹åŒºåˆ‡ã‚Šã‚’è©¦ã™
            try:
                df = pd.read_csv(io.StringIO(csv_text), delim_whitespace=True)
            except Exception as e2:
                st.error(f"{source_name}ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                return None
        
        # ã‚«ãƒ©ãƒ åã®ç¢ºèªã¨ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆç©ºç™½ã‚’é™¤å»ï¼‰
        df.columns = [col.strip() for col in df.columns]
        
        # å¿…é ˆã‚«ãƒ©ãƒ ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        required_columns = ['ymd', 'qty']
        if not all(col in df.columns for col in required_columns):
            # ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ©ãƒ ã®å ´åˆã¯ã€æœ€åˆã®2ã¤ã®ã‚«ãƒ©ãƒ ãŒymdã¨qtyã¨ä»®å®š
            if len(df.columns) >= 2:
                rename_dict = {df.columns[0]: 'ymd', df.columns[1]: 'qty'}
                df = df.rename(columns=rename_dict)
            else:
                st.error(f"{source_name}ã®å¿…é ˆã‚«ãƒ©ãƒ  'ymd' ã¨ 'qty' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
                return None
        
        # æ—¥ä»˜ã®å‡¦ç†
        df['ymd'] = df['ymd'].astype(str).str.zfill(8)
        try:
            # ã¾ãš%Y%m%då½¢å¼ã§å¤‰æ›ã‚’è©¦è¡Œ
            df['ymd'] = pd.to_datetime(df['ymd'], format='%Y%m%d', errors='coerce')
        except:
            try:
                # å¤±æ•—ã—ãŸå ´åˆã¯è‡ªå‹•æ¨å®šã§å¤‰æ›
                df['ymd'] = pd.to_datetime(df['ymd'], errors='coerce')
            except:
                st.error("æ—¥ä»˜åˆ—ã®å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚YYYYMMDDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                return None
        
        # ç„¡åŠ¹ãªæ—¥ä»˜ã‚’ãƒã‚§ãƒƒã‚¯
        invalid_dates = df[df['ymd'].isna()]
        if not invalid_dates.empty:
            st.warning(f"{len(invalid_dates)}è¡Œã®æ—¥ä»˜ãŒç„¡åŠ¹ãªãŸã‚é™¤å¤–ã•ã‚Œã¾ã—ãŸã€‚YYYYMMDDå½¢å¼ï¼ˆä¾‹ï¼š20240101ï¼‰ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            df = df.dropna(subset=['ymd'])
        
        # æ¬ æå€¤ã‚’é™¤å¤–
        original_len = len(df)
        df = df.dropna(subset=['ymd'])
            
        # qtyåˆ—ã®æ•°å€¤å¤‰æ›ç¢ºèª
        try:
            df['qty'] = pd.to_numeric(df['qty'], errors='coerce')
            if df['qty'].isna().any():
                df = df.dropna(subset=['qty'])
        except Exception as e:
            st.error(f"{source_name}ã®æ•°é‡(qty)ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
            return None
        
        # ã‚«ãƒ©ãƒ ãŒã™ã¹ã¦æƒã£ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        if 'ymd' not in df.columns or 'qty' not in df.columns:
            st.error(f"{source_name}ã®ãƒ‡ãƒ¼ã‚¿ã«ymdã¾ãŸã¯qtyã‚«ãƒ©ãƒ ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None
        
        # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
        if df.empty:
            st.error(f"{source_name}ã®æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return None
            
        return df
    except Exception as e:
        st.error(f"{source_name}ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        return None

# --- å‡¦ç½®ç¾¤ã®ã¿åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆé–¢æ•° ---
def create_single_group_dataset(df_treat, treatment_name, freq_option):
    """
    å‡¦ç½®ç¾¤ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹é–¢æ•°
    """
    try:
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®é›†è¨ˆ
        agg_treat = aggregate_df(df_treat, freq_option)
        
        # å…¨æœŸé–“ã®ç¯„å›²ã‚’ç”Ÿæˆï¼ˆå‡¦ç½®ç¾¤ã®ã¿ã®å ´åˆï¼‰
        # å‡¦ç½®ç¾¤ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’å–å¾—
        df_dates = pd.to_datetime(df_treat['ymd'])
        start_date = df_dates.min()
        end_date = df_dates.max()
        
        if freq_option == "æœˆæ¬¡":
            # æœˆã®åˆæ—¥ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã‚’ç”Ÿæˆ
            all_periods = pd.date_range(
                start=start_date.replace(day=1),
                end=end_date.replace(day=1),
                freq='MS'  # Month Start
            )
        elif freq_option == "æ—¬æ¬¡":
            # æ—¬åŒºåˆ‡ã‚Šã®æ—¥ä»˜ãƒªã‚¹ãƒˆã‚’ä½œæˆï¼ˆutils_step1.pyã¨åŒã˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
            first_month = start_date.replace(day=1)
            last_month = end_date.replace(day=1)
            months = pd.date_range(start=first_month, end=last_month, freq='MS')
            
            periods = []
            for month in months:
                # å„æœˆã®1æ—¥ã€11æ—¥ã€21æ—¥ã‚’è¿½åŠ ï¼ˆç¯„å›²å†…ã®å ´åˆã®ã¿ï¼‰
                for day in [1, 11, 21]:
                    date = month.replace(day=day)
                    if start_date <= date <= end_date:
                        periods.append(date)
            all_periods = pd.DatetimeIndex(periods)
        else:  # æ—¥æ¬¡
            all_periods = pd.date_range(start=start_date, end=end_date, freq='D')
        
        # å…¨æœŸé–“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¼ãƒ­åŸ‹ã‚
        all_periods_df = pd.DataFrame(index=all_periods)
        all_periods_df.index.name = 'period'
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒãƒ¼ã‚¸ã—ã¦ã‚¼ãƒ­åŸ‹ã‚
        agg_treat_full = pd.merge(
            all_periods_df, 
            agg_treat.set_index('period'), 
            how='left', 
            left_index=True, 
            right_index=True
        ).fillna(0)
        
        # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆå‡¦ç½®ç¾¤ã®ã¿ï¼‰
        dataset = pd.DataFrame({
            'ymd': all_periods,
            f'å‡¦ç½®ç¾¤ï¼ˆ{treatment_name}ï¼‰': agg_treat_full['qty'].values
        })
        
        return dataset
        
    except Exception as e:
        st.error(f"å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        return None

# --- æ¨™æº–åˆ†æã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
if analysis_type == "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰":
    if upload_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆâ€»æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã¯éå¯¾å¿œï¼è‹±æ•°å­—ã®ã¿ä½¿ç”¨å¯ï¼‰" and read_btn_upload and treatment_file and control_file:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
            try:
                # Streamlit Cloudç’°å¢ƒã‹ã©ã†ã‹ã‚’ç¢ºèªï¼ˆç’°å¢ƒå¤‰æ•°ãªã©ã§åˆ¤å®šå¯èƒ½ï¼‰
                is_cloud_env = os.environ.get('STREAMLIT_SHARING_MODE') == 'streamlit_sharing'
                
                # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª
                if treatment_file.size > 5 * 1024 * 1024 or control_file.size > 5 * 1024 * 1024:
                    st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ã€‚5MBä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
                    df_treat = None
                    df_ctrl = None
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ã‚¯ä½ç½®ã‚’ãƒªã‚»ãƒƒãƒˆï¼ˆè¤‡æ•°å›èª­ã¿è¾¼ã‚€å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
                    treatment_file.seek(0)
                    
                    # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åãƒã‚§ãƒƒã‚¯
                    if any(ord(c) > 127 for c in treatment_file.name) and is_cloud_env:
                        st.error(f"Streamlit Cloudç’°å¢ƒã§ã¯æ—¥æœ¬èªã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ{treatment_file.name}ï¼‰ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è‹±æ•°å­—ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
                        df_treat = None
                    else:
                        # å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿è©¦è¡Œ
                        df_treat = load_and_clean_uploaded_csv(treatment_file)
                    
                    # å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã¿è¾¼ã‚ãŸå ´åˆã®ã¿å¯¾ç…§ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
                    if df_treat is not None:
                        # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ã‚¯ä½ç½®ã‚’ãƒªã‚»ãƒƒãƒˆ
                        control_file.seek(0)
                        
                        # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åãƒã‚§ãƒƒã‚¯
                        if any(ord(c) > 127 for c in control_file.name) and is_cloud_env:
                            st.error(f"Streamlit Cloudç’°å¢ƒã§ã¯æ—¥æœ¬èªã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ{control_file.name}ï¼‰ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è‹±æ•°å­—ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
                            df_ctrl = None
                        else:
                            # å¯¾ç…§ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿è©¦è¡Œ
                            df_ctrl = load_and_clean_uploaded_csv(control_file)
                    else:
                        df_ctrl = None
                        st.error("å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã€å¯¾ç…§ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                
                if df_treat is not None and df_ctrl is not None and not df_treat.empty and not df_ctrl.empty:
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸåç§°ã‚’ä½¿ç”¨ï¼‰
                    st.session_state['df_treat'] = df_treat
                    st.session_state['df_ctrl'] = df_ctrl
                    # åå‰ãŒç©ºã§ãªã‘ã‚Œã°ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’ä½¿ç”¨ã€ç©ºãªã‚‰å‡¦ç†åã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«
                    treatment_name = treatment_name.strip() if treatment_name and treatment_name.strip() else "å‡¦ç½®ç¾¤"
                    control_name = control_name.strip() if control_name and control_name.strip() else "å¯¾ç…§ç¾¤"
                    st.session_state['treatment_name'] = treatment_name
                    st.session_state['control_name'] = control_name
                    st.session_state['data_loaded'] = True
                    st.success("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ä¸‹è¨˜ã«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                else:
                    st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    if df_treat is None:
                        st.error("å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    elif df_treat.empty:
                        st.error("å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    if df_ctrl is None:
                        st.error("å¯¾ç…§ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    elif df_ctrl is not None and df_ctrl.empty:
                        st.error("å¯¾ç…§ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                    st.session_state['data_loaded'] = False
                    
                    # ä»£æ›¿å…¥åŠ›æ–¹æ³•ã®ææ¡ˆ
                    st.info("CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚ä»¥ä¸‹ã¯å…¥åŠ›ä¾‹ã§ã™ï¼š\n\nymd,qty\n20170403,29\n20170425,24\n...")
            except Exception as e:
                st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.session_state['data_loaded'] = False
                
                # ä»£æ›¿å…¥åŠ›æ–¹æ³•ã®ææ¡ˆ
                st.info("CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚ä»¥ä¸‹ã¯å…¥åŠ›ä¾‹ã§ã™ï¼š\n\nymd,qty\n20170403,29\n20170425,24\n...")

    # --- æ¨™æº–åˆ†æã®ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
    elif upload_method == "CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›" and read_btn_text:
        with st.spinner("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
            df_treat = load_and_clean_csv_text(treatment_csv, "å‡¦ç½®ç¾¤")
            df_ctrl = load_and_clean_csv_text(control_csv, "å¯¾ç…§ç¾¤")
            
            if df_treat is not None and df_ctrl is not None and not df_treat.empty and not df_ctrl.empty:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸåç§°ã‚’ä½¿ç”¨ï¼‰
                st.session_state['df_treat'] = df_treat
                st.session_state['df_ctrl'] = df_ctrl
                # åå‰ãŒç©ºã§ãªã‘ã‚Œã°ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›å€¤ã‚’ä½¿ç”¨ã€ç©ºãªã‚‰å‡¦ç†åã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«
                treatment_name = treatment_name.strip() if treatment_name and treatment_name.strip() else "å‡¦ç½®ç¾¤"
                control_name = control_name.strip() if control_name and control_name.strip() else "å¯¾ç…§ç¾¤"
                st.session_state['treatment_name'] = treatment_name
                st.session_state['control_name'] = control_name
                st.session_state['data_loaded'] = True
                st.success("ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ä¸‹è¨˜ã«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å…¥åŠ›ã—ãŸCSVãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                if df_treat is None:
                    st.error("å‡¦ç½®ç¾¤ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                if df_ctrl is None:
                    st.error("å¯¾ç…§ç¾¤ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                st.session_state['data_loaded'] = False

# --- å‡¦ç½®ç¾¤ã®ã¿åˆ†æã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ ---
else:  # analysis_type == "å‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼ˆå¯¾ç…§ç¾¤ãªã—ï¼‰"
    if upload_method == "ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆâ€»æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åã¯éå¯¾å¿œï¼è‹±æ•°å­—ã®ã¿ä½¿ç”¨å¯ï¼‰" and read_btn_single_upload and treatment_file:
        with st.spinner("å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
            try:
                # Streamlit Cloudç’°å¢ƒã‹ã©ã†ã‹ã‚’ç¢ºèª
                is_cloud_env = os.environ.get('STREAMLIT_SHARING_MODE') == 'streamlit_sharing'
                
                # ã‚»ãƒ¼ãƒ•ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ - ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã®ç¢ºèª
                if treatment_file.size > 5 * 1024 * 1024:
                    st.error("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¾ã™ã€‚5MBä»¥ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚")
                    df_treat = None
                else:
                    # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚·ãƒ¼ã‚¯ä½ç½®ã‚’ãƒªã‚»ãƒƒãƒˆ
                    treatment_file.seek(0)
                    
                    # æ—¥æœ¬èªãƒ•ã‚¡ã‚¤ãƒ«åãƒã‚§ãƒƒã‚¯
                    if any(ord(c) > 127 for c in treatment_file.name) and is_cloud_env:
                        st.error(f"Streamlit Cloudç’°å¢ƒã§ã¯æ—¥æœ¬èªã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆ{treatment_file.name}ï¼‰ã¯ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è‹±æ•°å­—ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚")
                        df_treat = None
                    else:
                        # å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿è©¦è¡Œ
                        df_treat = load_and_clean_uploaded_csv(treatment_file)
                
                if df_treat is not None and not df_treat.empty:
                    # å‡¦ç½®ç¾¤ã®ã¿åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
                    is_valid, error_msg = validate_single_group_data(df_treat)
                    
                    if is_valid:
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆå‡¦ç½®ç¾¤ã®ã¿ï¼‰
                        st.session_state['df_treat'] = df_treat
                        st.session_state['df_ctrl'] = None  # å¯¾ç…§ç¾¤ãªã—
                        treatment_name = treatment_name.strip() if treatment_name and treatment_name.strip() else "å‡¦ç½®ç¾¤"
                        st.session_state['treatment_name'] = treatment_name
                        st.session_state['control_name'] = None
                        st.session_state['data_loaded'] = True
                        st.session_state['analysis_type'] = "å‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼ˆå¯¾ç…§ç¾¤ãªã—ï¼‰"  # åˆ†æã‚¿ã‚¤ãƒ—ã‚’æ˜ç¤ºçš„ã«ä¿å­˜
                        st.success("å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ä¸‹è¨˜ã«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                    else:
                        st.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {error_msg}")
                        st.session_state['data_loaded'] = False
                else:
                    st.error("å‡¦ç½®ç¾¤ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                    st.session_state['data_loaded'] = False
                
            except Exception as e:
                st.error(f"å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                st.session_state['data_loaded'] = False

    elif upload_method == "CSVãƒ†ã‚­ã‚¹ãƒˆç›´æ¥å…¥åŠ›" and read_btn_single_text:
        with st.spinner("å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­..."):
            df_treat = load_and_clean_csv_text(treatment_csv, "å‡¦ç½®ç¾¤")
            
            if df_treat is not None and not df_treat.empty:
                # å‡¦ç½®ç¾¤ã®ã¿åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
                is_valid, error_msg = validate_single_group_data(df_treat)
                
                if is_valid:
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜ï¼ˆå‡¦ç½®ç¾¤ã®ã¿ï¼‰
                    st.session_state['df_treat'] = df_treat
                    st.session_state['df_ctrl'] = None  # å¯¾ç…§ç¾¤ãªã—
                    treatment_name = treatment_name.strip() if treatment_name and treatment_name.strip() else "å‡¦ç½®ç¾¤"
                    st.session_state['treatment_name'] = treatment_name
                    st.session_state['control_name'] = None
                    st.session_state['data_loaded'] = True
                    st.session_state['analysis_type'] = "å‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼ˆå¯¾ç…§ç¾¤ãªã—ï¼‰"  # åˆ†æã‚¿ã‚¤ãƒ—ã‚’æ˜ç¤ºçš„ã«ä¿å­˜
                    st.success("å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚ä¸‹è¨˜ã«ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
                else:
                    st.error(f"ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {error_msg}")
                    st.session_state['data_loaded'] = False
            else:
                st.error("å‡¦ç½®ç¾¤ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚å…¥åŠ›ã—ãŸCSVãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                st.session_state['data_loaded'] = False

# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ¸ˆã¿ãªã‚‰è¡¨ç¤ºï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—ï¼‰ ---
if st.session_state.get('data_loaded', False):
    df_treat = st.session_state['df_treat']
    df_ctrl = st.session_state.get('df_ctrl', None)  # å‡¦ç½®ç¾¤ã®ã¿åˆ†æã§ã¯ None
    treatment_name = st.session_state['treatment_name']
    control_name = st.session_state.get('control_name', None)
    current_analysis_type = st.session_state.get('analysis_type', analysis_type)
    
    # --- ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
    st.markdown('<div class="section-title">èª­ã¿è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã®ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½10ä»¶è¡¨ç¤ºï¼‰</div>', unsafe_allow_html=True)
    
    if current_analysis_type == "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰" and df_ctrl is not None:
        # æ¨™æº–åˆ†æã®å ´åˆï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f'<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ï¼ˆ{treatment_name}ï¼‰</div>', unsafe_allow_html=True)
            preview_df_treat = df_treat[['ymd', 'qty']].head(10).copy()
            preview_df_treat['ymd'] = preview_df_treat['ymd'].dt.strftime('%Y-%m-%d')
            preview_df_treat.index = range(1, len(preview_df_treat) + 1)
            st.dataframe(preview_df_treat, use_container_width=True)
        with col2:
            st.markdown(f'<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å¯¾ç…§ç¾¤ï¼ˆ{control_name}ï¼‰</div>', unsafe_allow_html=True)
            preview_df_ctrl = df_ctrl[['ymd', 'qty']].head(10).copy()
            preview_df_ctrl['ymd'] = preview_df_ctrl['ymd'].dt.strftime('%Y-%m-%d')
            preview_df_ctrl.index = range(1, len(preview_df_ctrl) + 1)
            st.dataframe(preview_df_ctrl, use_container_width=True)
    else:
        # å‡¦ç½®ç¾¤ã®ã¿åˆ†æã®å ´åˆ
        st.markdown(f'<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ï¼ˆ{treatment_name}ï¼‰- å‡¦ç½®ç¾¤ã®ã¿åˆ†æ</div>', unsafe_allow_html=True)
        preview_df_treat = df_treat[['ymd', 'qty']].head(10).copy()
        preview_df_treat['ymd'] = preview_df_treat['ymd'].dt.strftime('%Y-%m-%d')
        preview_df_treat.index = range(1, len(preview_df_treat) + 1)
        
        # ä»‹å…¥ãƒã‚¤ãƒ³ãƒˆæ¨å¥¨ã®è¡¨ç¤º
        try:
            suggested_date, pre_days, post_days = suggest_intervention_point(df_treat)
            
            col1, col2 = st.columns([2, 1])
            with col1:
                st.dataframe(preview_df_treat, use_container_width=True)
            with col2:
                st.markdown("**ãƒ‡ãƒ¼ã‚¿è¦ä»¶ãƒã‚§ãƒƒã‚¯**")
                total_days = len(df_treat)
                st.write(f"ğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿æ—¥æ•°: {total_days}æ—¥")
                
                # suggested_dateãŒæ—¥ä»˜å‹ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¦é©åˆ‡ã«è¡¨ç¤º
                if isinstance(suggested_date, str):
                    st.write(f"ğŸ“… æ¨å¥¨ä»‹å…¥æ—¥: {suggested_date}")
                else:
                    try:
                        # datetimeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®å ´åˆ
                        if hasattr(suggested_date, 'strftime'):
                            st.write(f"ğŸ“… æ¨å¥¨ä»‹å…¥æ—¥: {suggested_date.strftime('%Y-%m-%d')}")
                        else:
                            # ãã®ä»–ã®å½¢å¼ã®å ´åˆã¯æ–‡å­—åˆ—ã¨ã—ã¦è¡¨ç¤º
                            st.write(f"ğŸ“… æ¨å¥¨ä»‹å…¥æ—¥: {str(suggested_date)}")
                    except Exception as e:
                        st.write(f"ğŸ“… æ¨å¥¨ä»‹å…¥æ—¥: {str(suggested_date)}")
                
                st.write(f"â³ ä»‹å…¥å‰æœŸé–“: {pre_days}æ—¥")
                st.write(f"â³ ä»‹å…¥å¾ŒæœŸé–“: {post_days}æ—¥")
                
                if total_days >= 37:
                    st.success("âœ… ãƒ‡ãƒ¼ã‚¿é‡å……è¶³")
                else:
                    st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ37æ—¥æœªæº€ï¼‰")
                    
        except Exception as e:
            col1, col2 = st.columns([2, 1])
            with col1:
                st.dataframe(preview_df_treat, use_container_width=True)
            with col2:
                st.markdown("**ãƒ‡ãƒ¼ã‚¿è¦ä»¶ãƒã‚§ãƒƒã‚¯**")
                total_days = len(df_treat)
                st.write(f"ğŸ“Š ç·ãƒ‡ãƒ¼ã‚¿æ—¥æ•°: {total_days}æ—¥")
                st.warning(f"âš ï¸ æ¨å¥¨ä»‹å…¥æ—¥ã®è¨ˆç®—ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                
                if total_days >= 37:
                    st.success("âœ… ãƒ‡ãƒ¼ã‚¿é‡å……è¶³")
                else:
                    st.warning("âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ï¼ˆ37æ—¥æœªæº€ï¼‰")

    # --- çµ±è¨ˆæƒ…å ± ---
    st.markdown('<div class="section-title">ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±</div>', unsafe_allow_html=True)
    
    if current_analysis_type == "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰" and df_ctrl is not None:
        # æ¨™æº–åˆ†æã®çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        col1, col2 = st.columns(2)
        with col1:
            st.markdown(f'<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ï¼ˆ{treatment_name}ï¼‰</div>', unsafe_allow_html=True)
            if 'qty' in df_treat.columns:
                stats_treat = format_stats_with_japanese(df_treat[['qty']])
                st.dataframe(stats_treat, use_container_width=True, hide_index=True)
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã« 'qty' ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        with col2:
            st.markdown(f'<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å¯¾ç…§ç¾¤ï¼ˆ{control_name}ï¼‰</div>', unsafe_allow_html=True)
            if 'qty' in df_ctrl.columns:
                stats_ctrl = format_stats_with_japanese(df_ctrl[['qty']])
                st.dataframe(stats_ctrl, use_container_width=True, hide_index=True)
            else:
                st.error("ãƒ‡ãƒ¼ã‚¿ã« 'qty' ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    else:
        # å‡¦ç½®ç¾¤ã®ã¿åˆ†æã®çµ±è¨ˆæƒ…å ±è¡¨ç¤º
        st.markdown(f'<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">å‡¦ç½®ç¾¤ï¼ˆ{treatment_name}ï¼‰</div>', unsafe_allow_html=True)
        if 'qty' in df_treat.columns:
            stats_treat = format_stats_with_japanese(df_treat[['qty']])
            st.dataframe(stats_treat, use_container_width=True, hide_index=True)
        else:
            st.error("ãƒ‡ãƒ¼ã‚¿ã« 'qty' ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # --- åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ ---
    st.markdown('<div class="section-title">åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ</div>', unsafe_allow_html=True)
    st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">åˆ†æãƒ‡ãƒ¼ã‚¿é›†è¨ˆæ–¹æ³•ã®é¸æŠ</div>', unsafe_allow_html=True)

    col1, col2 = st.columns([1, 3])
    with col1:
        freq_option = st.radio(
            "ãƒ‡ãƒ¼ã‚¿é›†è¨ˆæ–¹æ³•",
            options=["æœˆæ¬¡", "æ—¬æ¬¡"],
            label_visibility="collapsed"
        )
    with col2:
        if freq_option == "æœˆæ¬¡":
            st.markdown("""
<div style="font-size:0.98em;margin-top:0.1em;padding-left:0;">
<span style="font-weight:bold;">æœˆæ¬¡é›†è¨ˆï¼š</span>æœˆå˜ä½ã§é›†è¨ˆã—ã€æ—¥ä»˜ã¯ãã®æœˆã®1æ—¥ã«ãªã‚Šã¾ã™<br>
<span style="font-weight:normal;color:#666;">æ—¬æ¬¡é›†è¨ˆï¼š</span>æœˆã‚’ä¸Šæ—¬ãƒ»ä¸­æ—¬ãƒ»ä¸‹æ—¬ã«3åˆ†å‰²ã—ã¦é›†è¨ˆã—ã€æ—¥ä»˜ã¯ãã‚Œãã‚Œ1æ—¥ï¼ˆä¸Šæ—¬ï¼‰ã€11æ—¥ï¼ˆä¸­æ—¬ï¼‰ã€21æ—¥ï¼ˆä¸‹æ—¬ï¼‰ã«ãªã‚Šã¾ã™<br>
<div style="color:#1976d2;font-size:0.9em;margin-top:0.3em;padding-left:0;">â€»æ¬ æå€¤ã¯è‡ªå‹•çš„ã«0ã§åŸ‹ã‚ã‚‰ã‚Œã¾ã™ã€‚</div>
</div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
<div style="font-size:0.98em;margin-top:0.1em;padding-left:0;">
<span style="font-weight:normal;color:#666;">æœˆæ¬¡é›†è¨ˆï¼š</span>æœˆå˜ä½ã§é›†è¨ˆã—ã€æ—¥ä»˜ã¯ãã®æœˆã®1æ—¥ã«ãªã‚Šã¾ã™<br>
<span style="font-weight:bold;">æ—¬æ¬¡é›†è¨ˆï¼š</span>æœˆã‚’ä¸Šæ—¬ãƒ»ä¸­æ—¬ãƒ»ä¸‹æ—¬ã«3åˆ†å‰²ã—ã¦é›†è¨ˆã—ã€æ—¥ä»˜ã¯ãã‚Œãã‚Œ1æ—¥ï¼ˆä¸Šæ—¬ï¼‰ã€11æ—¥ï¼ˆä¸­æ—¬ï¼‰ã€21æ—¥ï¼ˆä¸‹æ—¬ï¼‰ã«ãªã‚Šã¾ã™<br>
<div style="color:#1976d2;font-size:0.9em;margin-top:0.3em;padding-left:0;">â€»æ¬ æå€¤ã¯è‡ªå‹•çš„ã«0ã§åŸ‹ã‚ã‚‰ã‚Œã¾ã™ã€‚</div>
</div>
            """, unsafe_allow_html=True)
    
    # ã€Œãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹ã€ãƒœã‚¿ãƒ³ã®ä¸Šã«ä½™ç™½ã‚’è¿½åŠ 
    st.markdown('<div style="margin-top:25px;"></div>', unsafe_allow_html=True)
    create_btn = st.button("ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹", key="create", help="Causal Impactåˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚", type="primary", use_container_width=True)
    
    if create_btn or ('dataset_created' in st.session_state and st.session_state['dataset_created']):
        if create_btn:  # æ–°ã—ããƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã™ã‚‹å ´åˆã®ã¿å®Ÿè¡Œ
            if current_analysis_type == "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰" and df_ctrl is not None:
                # æ¨™æº–åˆ†æã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®é›†è¨ˆ
                agg_treat = aggregate_df(df_treat, freq_option)
                agg_ctrl = aggregate_df(df_ctrl, freq_option)
                
                # å…±é€šæœŸé–“ã®å…¨æ—¥ä»˜ç¯„å›²ã‚’ç”Ÿæˆï¼ˆä¸¡ç¾¤ã®é–‹å§‹æ—¥ã®é…ã„æ–¹ã‹ã‚‰çµ‚äº†æ—¥ã®æ—©ã„æ–¹ã¾ã§ï¼‰
                all_periods = create_full_period_range(df_treat, df_ctrl, freq_option)
                
                # å…¨æœŸé–“ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½œæˆã—ã€ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¼ãƒ­åŸ‹ã‚
                all_periods_df = pd.DataFrame(index=all_periods)
                all_periods_df.index.name = 'period'
                
                # å„ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ãƒãƒ¼ã‚¸ã—ã¦ã‚¼ãƒ­åŸ‹ã‚
                agg_treat_full = pd.merge(
                    all_periods_df, 
                    agg_treat.set_index('period'), 
                    how='left', 
                    left_index=True, 
                    right_index=True
                ).fillna(0)
                
                agg_ctrl_full = pd.merge(
                    all_periods_df, 
                    agg_ctrl.set_index('period'), 
                    how='left', 
                    left_index=True, 
                    right_index=True
                ).fillna(0)
                
                # æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
                dataset = pd.DataFrame({
                    'ymd': all_periods,
                    f'å‡¦ç½®ç¾¤ï¼ˆ{treatment_name}ï¼‰': agg_treat_full['qty'].values,
                    f'å¯¾ç…§ç¾¤ï¼ˆ{control_name}ï¼‰': agg_ctrl_full['qty'].values
                })
                
                # ãƒ‡ãƒ¼ã‚¿æœŸé–“æƒ…å ±ã‚’ä¿å­˜ï¼ˆè¡¨ç¤ºç”¨ï¼‰
                treat_period = f"{df_treat['ymd'].min().strftime('%Y/%m/%d')} ï½ {df_treat['ymd'].max().strftime('%Y/%m/%d')}"
                ctrl_period = f"{df_ctrl['ymd'].min().strftime('%Y/%m/%d')} ï½ {df_ctrl['ymd'].max().strftime('%Y/%m/%d')}"
                common_period = f"{all_periods.min().strftime('%Y/%m/%d')} ï½ {all_periods.max().strftime('%Y/%m/%d')}"
                st.session_state['period_info'] = {
                    'treat_period': treat_period,
                    'ctrl_period': ctrl_period,
                    'common_period': common_period
                }
            else:
                # å‡¦ç½®ç¾¤ã®ã¿åˆ†æã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
                dataset = create_single_group_dataset(df_treat, treatment_name, freq_option)
                
                if dataset is not None:
                    # ãƒ‡ãƒ¼ã‚¿æœŸé–“æƒ…å ±ã‚’ä¿å­˜ï¼ˆå‡¦ç½®ç¾¤ã®ã¿ï¼‰
                    treat_period = f"{df_treat['ymd'].min().strftime('%Y/%m/%d')} ï½ {df_treat['ymd'].max().strftime('%Y/%m/%d')}"
                    st.session_state['period_info'] = {
                        'treat_period': treat_period,
                        'ctrl_period': None,  # å‡¦ç½®ç¾¤ã®ã¿åˆ†æã§ã¯å¯¾ç…§ç¾¤ãªã—
                        'common_period': treat_period  # å‡¦ç½®ç¾¤ã®ã¿ã®æœŸé–“
                    }
                else:
                    st.error("å‡¦ç½®ç¾¤ã®ã¿åˆ†æç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    dataset = None
            
            if dataset is not None:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state['dataset'] = dataset
                st.session_state['dataset_created'] = True
                
                # åˆ†ææœŸé–“ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’è¨­å®š
                dataset_min_date = dataset['ymd'].min().date()
                dataset_max_date = dataset['ymd'].max().date()
                
                # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å‰åŠéƒ¨åˆ†ã‚’ä»‹å…¥å‰æœŸé–“ã€å¾ŒåŠéƒ¨åˆ†ã‚’ä»‹å…¥æœŸé–“ã¨ã—ã¦ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
                mid_point_idx = len(dataset) // 2
                default_pre_end = dataset.iloc[mid_point_idx-1]['ymd'].date()
                default_post_start = dataset.iloc[mid_point_idx]['ymd'].date()
                
                # å‡¦ç½®ç¾¤ã®ã¿åˆ†æã®å ´åˆã¯æ¨å¥¨ä»‹å…¥ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
                if current_analysis_type == "å‡¦ç½®ç¾¤ã®ã¿åˆ†æï¼ˆå¯¾ç…§ç¾¤ãªã—ï¼‰":
                    try:
                        suggested_date, _, _ = suggest_intervention_point(df_treat)
                        # suggested_dateãŒæ—¥ä»˜å‹ã‹ã©ã†ã‹ã‚’ç¢ºèª
                        if hasattr(suggested_date, 'date'):
                            suggested_date_obj = suggested_date.date() if hasattr(suggested_date, 'date') else suggested_date
                        elif isinstance(suggested_date, str) and suggested_date != "ã‚¨ãƒ©ãƒ¼ï¼šæ¨å¥¨æ—¥è¨ˆç®—å¤±æ•—":
                            try:
                                suggested_date_obj = pd.to_datetime(suggested_date).date()
                            except:
                                suggested_date_obj = None
                        else:
                            suggested_date_obj = None
                        
                        if suggested_date_obj is not None:
                            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå†…ã§æ¨å¥¨æ—¥ã«æœ€ã‚‚è¿‘ã„æ—¥ä»˜ã‚’è¦‹ã¤ã‘ã‚‹
                            dataset_dates = dataset['ymd'].dt.date
                            closest_idx = (dataset_dates - suggested_date_obj).abs().idxmin()
                            suggested_dataset_date = dataset.iloc[closest_idx]['ymd'].date()
                            
                            # æ¨å¥¨æ—¥ã‚’åŸºæº–ã«æœŸé–“ã‚’è¨­å®š
                            if closest_idx > 0:
                                default_pre_end = dataset.iloc[closest_idx-1]['ymd'].date()
                                default_post_start = suggested_dataset_date
                    except Exception as e:
                        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä¸­ç‚¹ã‚’ä½¿ç”¨
                        pass
                
                st.session_state['period_defaults'] = {
                    'pre_start': dataset_min_date,
                    'pre_end': default_pre_end,
                    'post_start': default_post_start,
                    'post_end': dataset_max_date
                }
        else:
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒæ—¢ã«ä½œæˆæ¸ˆã¿ã®å ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‹ã‚‰å–å¾—
            dataset = st.session_state['dataset']
        
        if dataset is not None:
            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæƒ…å ±ã®è¡¨ç¤ºï¼ˆæ–°è¦ä½œæˆãƒ»æ—¢å­˜å•ã‚ãšï¼‰
            period_info = st.session_state.get('period_info', {})
            common_period = period_info.get('common_period', f"{dataset['ymd'].min().strftime('%Y/%m/%d')} ï½ {dataset['ymd'].max().strftime('%Y/%m/%d')}")
            
            st.markdown(f"""
<div style="margin-bottom:1.5em;">
<div style="display:flex;align-items:center;margin-bottom:0.5em;">
  <div style="font-weight:bold;font-size:1.05em;margin-right:0.5em;">å¯¾è±¡æœŸé–“ï¼š</div>
<div>{dataset['ymd'].min().strftime('%Y/%m/%d')} ï½ {dataset['ymd'].max().strftime('%Y/%m/%d')}</div>
  <div style="color:#1976d2;font-size:0.9em;margin-left:2em;">ã€€â€»{current_analysis_type}ã«åŸºã¥ã„ã¦ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆã—ã¦ã„ã¾ã™ã€‚</div>
</div>
<div style="display:flex;align-items:center;margin-bottom:0.5em;">
  <div style="font-weight:bold;font-size:1.05em;margin-right:0.5em;">ãƒ‡ãƒ¼ã‚¿æ•°ï¼š</div>
<div>{len(dataset)} ä»¶</div>
</div>
</div>
            """, unsafe_allow_html=True)
            
            # å…ƒãƒ‡ãƒ¼ã‚¿ã®æœŸé–“æƒ…å ±ãŒã‚ã‚‹å ´åˆã¯è©³ç´°ã‚’è¡¨ç¤º
            if 'period_info' in st.session_state:
                with st.expander("å…ƒãƒ‡ãƒ¼ã‚¿ã®æœŸé–“æƒ…å ±", expanded=False):
                    period_info = st.session_state['period_info']
                    if current_analysis_type == "æ¨™æº–åˆ†æï¼ˆå‡¦ç½®ç¾¤ + å¯¾ç…§ç¾¤ï¼‰":
                        st.markdown(f"""
<div style="margin-top:0.5em;">
<p><b>å‡¦ç½®ç¾¤æœŸé–“ï¼š</b>{period_info['treat_period']}</p>
<p><b>å¯¾ç…§ç¾¤æœŸé–“ï¼š</b>{period_info['ctrl_period']}</p>
<p><b>å…±é€šæœŸé–“ï¼š</b>{period_info['common_period']}</p>
<p style="margin-top:1em;font-size:0.9em;color:#666;">â€»å…±é€šæœŸé–“ã¯ã€Œå‡¦ç½®ç¾¤ã¨å¯¾ç…§ç¾¤ã®é–‹å§‹æ—¥ã®ã†ã¡é…ã„æ–¹ã€ã‹ã‚‰ã€Œçµ‚äº†æ—¥ã®ã†ã¡æ—©ã„æ–¹ã€ã¾ã§ã¨ã—ã¦è¨ˆç®—ã—ã¦ã„ã¾ã™ã€‚<br>â€»æ¬ æå€¤ã¯ã™ã¹ã¦ã‚¼ãƒ­åŸ‹ã‚ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
</div>
                        """, unsafe_allow_html=True)
                    else:
                        st.markdown(f"""
<div style="margin-top:0.5em;">
<p><b>å‡¦ç½®ç¾¤æœŸé–“ï¼š</b>{period_info['treat_period']}</p>
<p style="margin-top:1em;font-size:0.9em;color:#666;">â€»å‡¦ç½®ç¾¤ã®ã¿åˆ†æã§ã¯ã€å‡¦ç½®ç¾¤ã®ãƒ‡ãƒ¼ã‚¿æœŸé–“å…¨ä½“ã‚’å¯¾è±¡ã¨ã—ã¦ã„ã¾ã™ã€‚<br>â€»æ¬ æå€¤ã¯ã™ã¹ã¦ã‚¼ãƒ­åŸ‹ã‚ã•ã‚Œã¦ã„ã¾ã™ã€‚</p>
</div>
                        """, unsafe_allow_html=True)

            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã¨çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
            col1, col2 = st.columns(2)
            with col1:
                st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆä¸Šä½10ä»¶è¡¨ç¤ºï¼‰</div>', unsafe_allow_html=True)
                preview_df = dataset.head(10).copy()
                preview_df['ymd'] = preview_df['ymd'].dt.strftime('%Y-%m-%d')
                preview_df.index = range(1, len(preview_df) + 1)
                st.dataframe(preview_df, use_container_width=True)
            with col2:
                st.markdown('<div style="font-weight:bold;margin-bottom:0.5em;font-size:1.05em;">çµ±è¨ˆæƒ…å ±</div>', unsafe_allow_html=True)
                
                # çµ±è¨ˆæƒ…å ±ã®åˆ—åã‚’å‹•çš„ã«å–å¾—
                numeric_columns = [col for col in dataset.columns if col != 'ymd']
                
                stats_data = []
                for col in numeric_columns:
                    stats_data.append([
                        len(dataset),
                        round(dataset[col].mean(), 2),
                        round(dataset[col].std(), 2),
                        dataset[col].min(),
                        dataset[col].quantile(0.25),
                        dataset[col].quantile(0.5),
                        dataset[col].quantile(0.75),
                        dataset[col].max()
                    ])
                
                stats_df = pd.DataFrame(stats_data).T
                stats_df.columns = numeric_columns
                stats_df.index = ['countï¼ˆå€‹æ•°ï¼‰', 'meanï¼ˆå¹³å‡ï¼‰', 'stdï¼ˆæ¨™æº–åå·®ï¼‰', 'minï¼ˆæœ€å°å€¤ï¼‰', '25%ï¼ˆç¬¬1å››åˆ†ä½æ•°ï¼‰', '50%ï¼ˆä¸­å¤®å€¤ï¼‰', '75%ï¼ˆç¬¬3å››åˆ†ä½æ•°ï¼‰', 'maxï¼ˆæœ€å¤§å€¤ï¼‰']
                stats_df.insert(0, 'çµ±è¨ˆé …ç›®', stats_df.index)
                st.dataframe(stats_df, use_container_width=True, hide_index=True)

st.markdown("---")
st.markdown("### ğŸš§ é–‹ç™ºä¸­")
st.markdown("**å‡¦ç½®ç¾¤ã®ã¿åˆ†ææ©Ÿèƒ½**ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚æ—¢å­˜ã®æ¨™æº–åˆ†ææ©Ÿèƒ½ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€ä»¥ä¸‹ã®æ‹¡å¼µã‚’å®Ÿè£…äºˆå®šï¼š")
st.markdown("""
- âœ… å‡¦ç½®ç¾¤ã®ã¿ãƒ‡ãƒ¼ã‚¿ã®å–ã‚Šè¾¼ã¿æ©Ÿèƒ½
- ğŸ”„ ä»‹å…¥ãƒã‚¤ãƒ³ãƒˆè‡ªå‹•æ¨å¥¨æ©Ÿèƒ½  
- ğŸ”„ å­£ç¯€æ€§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
- ğŸ”„ çµæœè§£é‡ˆã®å¼·åŒ–ï¼ˆå¯¾ç…§ç¾¤ãªã—åˆ†æç‰¹æœ‰ã®æ³¨æ„äº‹é …ï¼‰
""") 